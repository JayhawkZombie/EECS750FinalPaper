%
%  $Author: ienne $
%  $Date: 1995/09/15 15:20:59 $
%  $Revision: 1.4 $
%

% \documentclass[10pt,journal,cspaper,compsoc]{IEEEtran}   %%%tc version
\documentclass[10pt, conference]{IEEEtran}
%\documentclass[conference,compsoc]{IEEEtran}
%\documentclass[10pt, conference]{IEEEtran}
%\documentclass[times, 10pt,onecolumn]{article}
\usepackage{amsmath, amssymb, enumerate}

%%%%%%%%%%%%%%%% page control%%%%%%%%%%%%%%%%%
%\usepackage[margin=0.75in]{geometry}

%\linespread{0.991}  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% this is really useful
%\usepackage{cite}
\usepackage{fancybox}
\usepackage{amsfonts}
%\usepackage{algorithm}
%\usepackage[noend]{algorithmic}
\usepackage[usenames]{color}
%\usepackage{colortbl}
%\usepackage[ figure, boxed, vlined]{algorithm2e}
%\usepackage[linesnumbered,vlined]{algorithm2e}
%\usepackage[lined,boxed]{algorithm2e}
\usepackage{listings}

\usepackage[linesnumbered,vlined]{algorithm2e}
\usepackage{graphicx}
\usepackage{times}
\usepackage{psfrag}
\usepackage{subfigure}
\usepackage{caption}
%\usepackage{subcaption}
\usepackage{multirow}
%\usepackage{setspace}
%\usepackage{listings}
\usepackage{epsfig}
%\usepackage{epstopdf}
%\usepackage[font=small,labelfont=bf]{caption}
\usepackage{url}
\usepackage{float}

\usepackage{color}
\def\fixme#1{\typeout{FIXED in page \thepage : {#1}}
%\bgroup \color{red}{} \egroup}
\bgroup \color{red}{[FIXME: {#1}]} \egroup}

%\usepackage[pdftex]{hyperref}
\usepackage{rotating,tabularx}

\interfootnotelinepenalty=10000

%% Define a new 'leo' style for the package that will use a smaller font.
\makeatletter
\def\url@leostyle{%
  \@ifundefined{selectfont}{\def\UrlFont{\sf}}{\def\UrlFont{\small\ttfamily}}}
\makeatother

%\documentstyle[times,art10,twocolumn,latex8]{article}

%-------------------------------------------------------------------------
% take the % away on next line to produce the final camera-ready version
\pagestyle{plain}
%\thispagestyle{empty}
%\pagestyle{empty}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}

%% remaining budget share, used in task stall section.
\newcommand{\bottomrule}{\hline}
\newcommand{\toprule}{\hline}
\newcommand{\midrule}{\hline}

%-------------------------------------------------------------------------
\begin{document}

\title{The Linux Scheduler: Complicatedly Simple Calculations}
\author{Kurt Slagle, Dustin Hauptman\\
\{kslagle,dhauptman\}@ku.edu\\
University of Kansas, USA\\ 
}

\maketitle
\thispagestyle{empty}
\begin{abstract}

\textbf{The Linux scheduler is written to be adaptive, flexible, and customizable.  However, with this modularity comes complexity.  As the kernel cannot easily perform floating point computations, there are present, inside the scheduler's per-task computations, a number of operations that are seemingly overly complex in an attempt to reproduce the floating point operations using fixed-point operations.  This paper looks in-depth at one function called repeatedly inside the kernels Completely Fair Scheduler, and presents a statistical analysis of the values passed to and from this function, as well as the accuracy of the performed computations.}

\end{abstract}

%-------------------------------------------------------------------------

\section{Introduction}

\definecolor{commentgreen}{rgb}{0,0.4,0}
\lstset{
	language=C, 
	basicstyle=\footnotesize, 
	breaklines=true, 
	keywordstyle=\color{blue},
	commentstyle=\color{commentgreen},
	emph={int,u32,u64,load_weight,mul_u64_u32_shr},
	emphstyle=\color{blue}
}

For newcomers to the Linux kernel, it would not be difficult to find oneself struggling to understand why a piece of code is written the way that it is.  Comments in the source code are often detailed, but do not always explain the choices that influenced the implementation of a function.  Floating point calculations are disabled inside the kernel, and enabling them is not free from overhead, so the code in the kernel is written to avoid using them.  This code can often be difficult to follow, and it is not often clear why the code is written in that way.

When exploring the implementation of the Completely Fair Scheduler (CFS) in the Linux kernel, we were intrigued by the code used in $\_\_calc\_delta$ in $fair.c$.  The concept of the Completely Fair Scheduler (CFS) is deceptively simple.  The source code for this inside the Linux kernel appears, initially, far more complex than would seem necessary.  We suspected this code is written this way to help ensure the result of the calculation is correct on a variety of machines.  The code is optimized to perform well for a number of special cases, but this comes at the sacrifice of readability.

We hypothesize that this implementation could be simplified if it was assumed it was to be run on a 64-bit system.  In this paper, we present an discussion of the changes made, an analysis of the performance impacts of those changes, and an analysis of the accuracy of the values obtained from both implementations.  

\section{Background}
The Completely Fair Scheduler seeks to be "fair" to all processes running, weighting processes to provide more CPU to those processes with a high priority without starving lower-priority tasks.  Each task maintains a virtual time, which is equivalent to the execution time divided by its weight.  The focus of this paper is on the code inside $\_\_calc\_delta$, namely on the calculation of $delta\_exec * 1 / weight$.  Floating point math cannot be used to simplify this, since floating point operations are disabled in the kernel.  They can be enabled, but doing so would likely only prove to be a detriment to performance.

What can be considered is the removal of the special-case optimizations to improve readability.  $\_\_calc\_delta$ is intended to compute $delta\_exec * 1 / weight$, and the code for this in the default Linux kernel is shown in Listing~\ref{lst:listing1}.  The code shown simply calculates the new $delta\_exec$ by multiplying it with the weight and inverted load weight.  The purpose of implementing it in this way is not immediately clear and not elaborated on in detail.  We seek to analyze the benefits gained or lost by implementing the code in this way.

For the aforementioned code, the accuracy of the calculation is determined by tracking the value computed by the kernel and the value computed by using floating point operations in user space.  This will be compared to the accuracy achieved by using a simpler version of the code, seen in Listing~\ref{lst:listing2}.
Because speed is critical inside the scheduler, the time spent inside both versions of the code is compared.  Since the kernel will perform different operations when using cgroups and not using cgroups for processes, the same analysis is done with benchmarks run with and without using cgroups.



\lstinputlisting[caption=\_\_calc\_delta inside fair.c, label=lst:listing1]{__calc_delta.c}

\lstinputlisting[caption=Altered \_\_calc\_delta in fair.c, label=lst:listing2]{__calc_delta_new.c}

\section{Your System}

The Linux kernel uses a plethora of macros whose values are configuration-dependent, and thus it should not be assumed that the analysis presented here is reflective of how the changes would perform on other system configurations.  The system on which this was tested is a Dell Latitude 5580, with an Intel Core i7 7820HQ @ 2.9 GHz (turbo up to 3.9 GHz), 16GB of DDR4 @ 2400 MHz memory, and 500GB HDD @ 7200 rpm.  To keep the CPU running at a relatively constant rate, dynamic frequency scaling was disabled.

\section{Evaluation}
Once the changes were made in the kernel we needed to see if there was any noticeable performance loss at both the micro and macro level. All information that was needed from the function was then printed out using $trace\_printk$.

For the micro level analysis, the number of cycles were found using the RTDSC instruction present on Intel chips.

At the macro level two sets of data, one using CGROUPS and the other without, were gathered for both kernel versions. When implementing the CGROUPS, six $cpu\_hog$ programs (Listing~\ref{lst:listing3}) were run and relegated to a single core. The following hierarchy for the CGROUPS were then used $/cgroup1/cgroup1\_1$, $/cgroup1/cgroup1\_2$, and $/cgroup2$. Each group was then given two $cpu\_hog$ programs. When not using CGROUPS, the benchmark hackbench was used and allowed to run on all cores. The macro level data was used for both accuracy calculations and timing analysis.

Once we obtained the cycle counts and input data we looked at if there were any noticeable slowdowns and if the accuracy had degraded or not.

\subsection{Accuracy}
When calculating the accuracy of the code in both kernel versions, we are assuming that the "ideal" value that could be calculated is the $delta\_exec * 1 / weight$ using floating point arithmetic. Since floating point operations are disabled in the kernel by default, we reimplemented all necessary kernel functions in user space and compared them against a floating point version of the ideal calculation. The results of this can be seen in both Table~\ref{tab:table1} and Table~\ref{tab:table2}. Not surprising is that our  $\_\_calc\_delta$ closely mirrors the floating point operation, as the same computation will be performed. More surprising is the that the old  $\_\_calc\_delta$ can generate results that are only around 84.63\% accurate, where ours never loose accuracy beyond 99.97\%.

\begin{lstlisting}
int main(void) {
	while(1);
	return;
}
\end{lstlisting}
\captionof{lstlisting}{cpu\_hog program} \label{lst:listing3}

    \begin{center}
	\resizebox{\columnwidth}{!}{%
		\begin{tabular}{| c |c | c | c | c | c |}
			\hline
			& Min & Max & Mean & Variance & STDDEV \\ \hline
			Old Kernel & 0.846281 & 1 & 0.996221 & 1.20622e-05 & 0.00347307 \\ \hline
			New Kernel & 0.999685 & 1 & 0.999978 & 4.807e-10 & 2.19249e-05 \\
			\hline
	\end{tabular}}
	\captionof{table}{Accuracy w/o CGROUP} \label{tab:table1}
\end{center}

\begin{center}
	\resizebox{\columnwidth}{!}{%
		\begin{tabular}{| c | c | c | c | c | c |}
			\hline
			& Min & Max & Mean & Variance & STDDEV \\ \hline
			Old Kernel & 0.994311 & 1 & 0.997727 & 4.17965e-06 & 0.00204442 \\ \hline
			New Kernel & 0.99984 & 1 & 1 & 5.17154e-12 & 2.2741e-06 \\
			\hline
	\end{tabular}}
	\captionof{table}{Accuracy w/ CGROUP} \label{tab:table2}
\end{center}

\begin{center}
	\resizebox{\columnwidth}{!}{%
		\begin{tabular}{| c | c | c | c | c | c | c |}
			\hline
			& Min & Max & Mean & Variance & STDDEV & Count\\ \hline
			Old Kernel & 19 & 3156 & 72.7423 & 889.85 & 29.8304 & 40427 \\ \hline
			New Kernel & 22 & 909 & 46.9553 & 378.735 & 19.4611 & 40428 \\
			\hline
	\end{tabular}}
	\captionof{table}{Total Cycles w/o CGROUP} \label{tab:table3}
\end{center}

\begin{center}
	\resizebox{\columnwidth}{!}{%
		\begin{tabular}{| c | c | c | c | c | c | c |}
			\hline
			& Min & Max & Mean & Variance & STDDEV & Count \\ \hline
			Old Kernel & 18 & 4295 & 75.1081 & 2854.71 & 53.4295 & 77997 \\ \hline
			New Kernel & 19 & 1642 & 37.9399 & 964.117 & 31.0502 & 77997 \\
			\hline
	\end{tabular}}
	\captionof{table}{Total Cycles w/ CGROUP} \label{tab:table4}
\end{center}
...
\section{Conclusion}
...
%-------------------------------------------------------------------------

\nocite{*}
\end{document}
